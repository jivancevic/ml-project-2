{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lnfEHquq_Ac"
      },
      "source": [
        "# **CIFAR-10 dataset analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_AZQrnvmFSU"
      },
      "source": [
        "In this work, we will implement CNN, ResNet and DenseNet and evaluate it on a CIFAR-10 dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeAkAiD7mFSU"
      },
      "outputs": [],
      "source": [
        "## Standard libraries\n",
        "import os\n",
        "import numpy as np \n",
        "import random\n",
        "from PIL import Image\n",
        "from types import SimpleNamespace\n",
        "\n",
        "## Imports for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "from IPython.display import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg', 'pdf') # For export\n",
        "import matplotlib\n",
        "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
        "import seaborn as sns\n",
        "sns.reset_orig()\n",
        "\n",
        "## PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "\n",
        "## Tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "# Torchvision\n",
        "import torchvision\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHT_3C34vs2p"
      },
      "source": [
        "##  **Load and Visualize Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a20PwaX0v7-Z"
      },
      "source": [
        "Download and prepare the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQu3nuhywAe2"
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55pnfS__wUA4"
      },
      "outputs": [],
      "source": [
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i])\n",
        "    # The CIFAR labels happen to be arrays, \n",
        "    # which is why you need the extra index\n",
        "    plt.xlabel(class_names[train_labels[i][0]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xU4n2zgC84DJ"
      },
      "outputs": [],
      "source": [
        "# Calculate mean and standard deviation\n",
        "mean = np.mean(train_images, axis=(0, 1, 2))\n",
        "std = np.std(train_images, axis=(0, 1, 2))\n",
        "\n",
        "print(\"Mean:\")\n",
        "print(mean)\n",
        "print(\"\\nStandard Deviation:\")\n",
        "print(std)\n",
        "\n",
        "# Calculate channel distribution\n",
        "channel_mean = np.mean(train_images, axis=(0, 1, 2))\n",
        "channel_std = np.std(train_images, axis=(0, 1, 2))\n",
        "\n",
        "print(\"\\nChannel Distribution:\")\n",
        "for i, channel_name in enumerate(['Red', 'Green', 'Blue']):\n",
        "    print(f\"{channel_name} Mean: {channel_mean[i]}\")\n",
        "    print(f\"{channel_name} Standard Deviation: {channel_std[i]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzZN6TMb9M58"
      },
      "outputs": [],
      "source": [
        "# Get unique class labels\n",
        "classes = np.unique(train_labels)\n",
        "\n",
        "# Create a figure with subplots\n",
        "fig, axs = plt.subplots(2, 5, figsize=(10, 6))\n",
        "\n",
        "# Iterate over each class\n",
        "for i, class_label in enumerate(classes):\n",
        "    # Find the first image in the training data with the current class label\n",
        "    image_index = np.where(train_labels == class_label)[0][0]\n",
        "    image_data = train_images[image_index]\n",
        "\n",
        "    # Compute the subplot coordinates\n",
        "    row = i // 5\n",
        "    col = i % 5\n",
        "\n",
        "    # Display the image on the corresponding subplot\n",
        "    axs[row, col].imshow(image_data)\n",
        "    axs[row, col].axis('off')\n",
        "    axs[row, col].set_title(f\"Class: {class_label}\")\n",
        "\n",
        "# Adjust the spacing between subplots\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "be_jrFft9O6q"
      },
      "outputs": [],
      "source": [
        "# Get unique class labels\n",
        "classes = np.unique(train_labels)\n",
        "\n",
        "# Count the occurrences of each class in the train and test sets\n",
        "train_counts = np.bincount(train_labels.flatten())\n",
        "test_counts = np.bincount(test_labels.flatten())\n",
        "\n",
        "# Create a figure and axes\n",
        "fig, ax = plt.subplots(figsize=(10, 3))\n",
        "\n",
        "# Set the x-axis range and tick labels\n",
        "x = np.arange(len(classes))\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(classes, rotation='vertical')\n",
        "\n",
        "# Set the y-axis range\n",
        "max_count = max(np.max(train_counts), np.max(test_counts))\n",
        "ax.set_ylim([0, max_count + 500])\n",
        "\n",
        "# Plot the train and test counts as bar plots\n",
        "width = 0.35\n",
        "ax.bar(x - width/2, train_counts, width, label='Train')\n",
        "ax.bar(x + width/2, test_counts, width, label='Test')\n",
        "\n",
        "# Set the labels and title\n",
        "ax.set_xlabel('Classes')\n",
        "ax.set_ylabel('Count')\n",
        "ax.set_title('Distribution of Data over Classes (Train vs Test)')\n",
        "\n",
        "# Add a legend\n",
        "ax.legend()\n",
        "\n",
        "# Display the plot\n",
        "plt.savefig('data_distribution.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_lxuzr9-TJr"
      },
      "outputs": [],
      "source": [
        "labels_mapping = [ \"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\" ]\n",
        "\n",
        "fig, axes = plt.subplots(5, 2, figsize=(8, 10))\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    class_images = train_images[train_labels.flatten() == i]\n",
        "    flattened_images = class_images.flatten()\n",
        "    ax.hist(flattened_images, bins=256, color='blue', alpha=0.5)\n",
        "    ax.set_title('Histogram - Class {}'.format(labels_mapping[i]))\n",
        "    ax.set_xlabel('Pixel Intensity')\n",
        "    ax.set_ylabel('Frequency')\n",
        "    ax.set_ylim(0, 200000)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('histogram.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SfgDxzi8jKl"
      },
      "source": [
        "## **CNN**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7V8P0QLwWLH"
      },
      "source": [
        "Start with simple CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKIZb5GEwZro"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvvNO2Q8wbp8"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIgYvsDIweo0"
      },
      "source": [
        "Adding Dense layers on top"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnxKXSV9wjA0"
      },
      "outputs": [],
      "source": [
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFtFJlEnwlCL"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFIeIepSwmW2"
      },
      "source": [
        "Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDIr_R3gwnl6"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels, epochs=10, \n",
        "                    validation_data=(test_images, test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HeF922jwpXP"
      },
      "source": [
        "Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfxLvgsewqz0"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWjCZYRVwsRA"
      },
      "outputs": [],
      "source": [
        "print(test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYd4wRLRBgO_"
      },
      "source": [
        "Hyperparamter optimization for CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QxCKpII5Cypd"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "shutil.rmtree('random_search', ignore_errors=True)\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import KFold\n",
        "from kerastuner.tuners import RandomSearch\n",
        "from kerastuner.engine.hyperparameters import HyperParameters\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "\n",
        "# Normalize the pixel values\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Define the model builder function\n",
        "def build_model(hp):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(hp.Choice('conv1_units', values=[64, 128, 256]), (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(hp.Choice('conv2_units', values=[128, 256, 512]), (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(hp.Choice('conv3_units', values=[128, 256, 512]), (3, 3), activation='relu'))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(hp.Choice('dense_units', values=[64, 128, 256, 512]), activation='relu'))\n",
        "    model.add(layers.Dropout(hp.Float('dropout_rate', min_value=0.0, max_value=0.5, step=0.1)))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define the number of folds\n",
        "k = 5\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "kf = KFold(n_splits=k, shuffle=True)\n",
        "\n",
        "# Initialize the RandomSearch tuner\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5,  # Number of hyperparameter combinations to try\n",
        "    executions_per_trial=1,  # Number of models to train per trial\n",
        "    directory='random_search',\n",
        "    project_name='cifar10'\n",
        ")\n",
        "\n",
        "# Iterate over the folds\n",
        "for train_index, val_index in kf.split(train_images):\n",
        "    # Split the data into training and validation sets for the current fold\n",
        "    x_train, x_val = train_images[train_index], train_images[val_index]\n",
        "    y_train, y_val = train_labels[train_index], train_labels[val_index]\n",
        "\n",
        "    # Perform the hyperparameter search for the current fold\n",
        "    tuner.search(x_train, y_train, epochs=10, validation_data=(x_val, y_val))\n",
        "\n",
        "# Get the best model across all folds\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Evaluate the best model on the test data\n",
        "test_loss, test_acc = best_model.evaluate(test_images, test_labels)\n",
        "print('Test accuracy:', test_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXRsNik1I2z5"
      },
      "outputs": [],
      "source": [
        "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "\n",
        "# Retrieve the values of the best hyperparameters\n",
        "best_learning_rate = best_hyperparameters.get('learning_rate')\n",
        "best_conv1_units = best_hyperparameters.get('conv1_units')\n",
        "best_conv2_units = best_hyperparameters.get('conv2_units')\n",
        "best_conv3_units = best_hyperparameters.get('conv3_units')\n",
        "best_dense_units = best_hyperparameters.get('dense_units')\n",
        "best_dropout_rate = best_hyperparameters.get('dropout_rate')\n",
        "\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print('Best Hyperparameters:')\n",
        "print('Learning rate:', best_learning_rate)\n",
        "print('Conv1 units:', best_conv1_units)\n",
        "print('Conv2 units:', best_conv2_units)\n",
        "print('Conv3 units:', best_conv3_units)\n",
        "print('Dropout Rate:', best_dropout_rate)\n",
        "print('Dense Units:', best_dense_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0OEc8hXwhfsO"
      },
      "outputs": [],
      "source": [
        "# Get the optimal hyperparameters\n",
        "best_hp = tuner.get_best_hyperparameters()[0]\n",
        "\n",
        "# Build the model with the optimal hyperparameters and fit it on the data\n",
        "model = build_model(best_hp)\n",
        "history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the manual hyperparameters\n",
        "from keras_tuner.engine.hyperparameters import HyperParameters\n",
        "manual_hps_1 = HyperParameters()\n",
        "manual_hps_1.Choice('conv1_units', values=[64])\n",
        "manual_hps_1.Choice('conv2_units', values=[128])\n",
        "manual_hps_1.Choice('conv3_units', values=[128])\n",
        "manual_hps_1.Choice('dense_units', values=[128])\n",
        "manual_hps_1.Float('dropout_rate', min_value=0.1, max_value=0.2)\n",
        "manual_hps_1.Choice('learning_rate', values=[1e-4])\n",
        "\n",
        "# Build the models with the manual hyperparameters and fit them on the data\n",
        "model_manual_1 = build_model(manual_hps_1)\n",
        "history_manual_1 = model_manual_1.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))"
      ],
      "metadata": {
        "id": "v1b9loFFGoD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "manual_hps_2 = HyperParameters()\n",
        "manual_hps_2.Choice('conv1_units', values=[256])\n",
        "manual_hps_2.Choice('conv2_units', values=[512])\n",
        "manual_hps_2.Choice('conv3_units', values=[512])\n",
        "manual_hps_2.Choice('dense_units', values=[1024])\n",
        "manual_hps_2.Float('dropout_rate', min_value=0.4, max_value=0.5)\n",
        "manual_hps_2.Choice('learning_rate', values=[1e-2])\n",
        "\n",
        "model_manual_2 = build_model(manual_hps_2)\n",
        "history_manual_2 = model_manual_2.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))"
      ],
      "metadata": {
        "id": "dkbZHPgQGoQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the validation accuracy over epochs for all models\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(history.history['val_accuracy'], label='Optimal model')\n",
        "plt.plot(history_manual_1.history['val_accuracy'], label='Lower bound')\n",
        "plt.plot(history_manual_2.history['val_accuracy'], label='Upper bound')\n",
        "plt.title('Validation Accuracy over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R77YuLLwGoc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3w8TWsjwzwH"
      },
      "source": [
        "## **ResNet and DenseNet**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aP5tI1NQmFSV"
      },
      "source": [
        "Setting random seed for random train test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lUsb0CmmFSV"
      },
      "outputs": [],
      "source": [
        "# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n",
        "DATASET_PATH = \"./data\"\n",
        "# Path to the folder where the pretrained models are saved\n",
        "CHECKPOINT_PATH = \"../saved_models/tutorial5\"\n",
        "\n",
        "# Function for setting the seed\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "set_seed(42)\n",
        "\n",
        "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiOzpqTEmFSW"
      },
      "source": [
        "Load pretrained models from a different tutorial and Tensorboard for visualizing the machine learning workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvH0o0IrmFSW"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "from urllib.error import HTTPError\n",
        "# Github URL where saved models are stored for this tutorial\n",
        "base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial5/\"\n",
        "# Files to download\n",
        "pretrained_files = [\"GoogleNet.ckpt\", \"ResNet.ckpt\", \"ResNetPreAct.ckpt\", \"DenseNet.ckpt\",\n",
        "                    \"tensorboards/GoogleNet/events.out.tfevents.googlenet\",\n",
        "                    \"tensorboards/ResNet/events.out.tfevents.resnet\",\n",
        "                    \"tensorboards/ResNetPreAct/events.out.tfevents.resnetpreact\",\n",
        "                    \"tensorboards/DenseNet/events.out.tfevents.densenet\"]\n",
        "# Create checkpoint path if it doesn't exist yet\n",
        "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
        "\n",
        "# For each file, check whether it already exists. If not, try downloading it.\n",
        "for file_name in pretrained_files:\n",
        "    file_path = os.path.join(CHECKPOINT_PATH, file_name)\n",
        "    if \"/\" in file_name:\n",
        "        os.makedirs(file_path.rsplit(\"/\",1)[0], exist_ok=True)\n",
        "    if not os.path.isfile(file_path):\n",
        "        file_url = base_url + file_name\n",
        "        print(f\"Downloading {file_url}...\")\n",
        "        try:\n",
        "            urllib.request.urlretrieve(file_url, file_path)\n",
        "        except HTTPError as e:\n",
        "            print(\"Something went wrong. Please try to download the file from the GDrive folder, or contact the author with the full output including the following error:\\n\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agPjLH-QmFSW"
      },
      "source": [
        "### Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mc_2cLsnxyGE"
      },
      "source": [
        "Calculate the mean and the standard deviation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5MjYewDmFSW"
      },
      "outputs": [],
      "source": [
        "train_dataset = CIFAR10(root=DATASET_PATH, train=True, download=True)\n",
        "DATA_MEANS = (train_dataset.data / 255.0).mean(axis=(0,1,2))\n",
        "DATA_STD = (train_dataset.data / 255.0).std(axis=(0,1,2))\n",
        "print(\"Data mean\", DATA_MEANS)\n",
        "print(\"Data std\", DATA_STD)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doujEGA3mFSX"
      },
      "source": [
        "Normalizing the data. Adding data augmentation for the training part.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "la2gVmq1mFSX"
      },
      "outputs": [],
      "source": [
        "test_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                     transforms.Normalize(DATA_MEANS, DATA_STD)\n",
        "                                     ])\n",
        "# For training, we add some augmentation. Networks are too powerful and would overfit.\n",
        "train_transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.RandomResizedCrop((32,32),scale=(0.8,1.0),ratio=(0.9,1.1)),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize(DATA_MEANS, DATA_STD)\n",
        "                                     ])\n",
        "# Loading the training dataset. We need to split it into a training and validation part\n",
        "# We need to do a little trick because the validation set should not use the augmentation.\n",
        "train_dataset = CIFAR10(root=DATASET_PATH, train=True, transform=train_transform, download=True)\n",
        "val_dataset = CIFAR10(root=DATASET_PATH, train=True, transform=test_transform, download=True)\n",
        "set_seed(42)\n",
        "train_set, _ = torch.utils.data.random_split(train_dataset, [45000, 5000])\n",
        "set_seed(42)\n",
        "_, val_set = torch.utils.data.random_split(val_dataset, [45000, 5000])\n",
        "\n",
        "# Loading the test set\n",
        "test_set = CIFAR10(root=DATASET_PATH, train=False, transform=test_transform, download=True)\n",
        "\n",
        "# We define a set of data loaders that we can use for various purposes later.\n",
        "train_loader = data.DataLoader(train_set, batch_size=128, shuffle=True, drop_last=True, pin_memory=True, num_workers=2)\n",
        "val_loader = data.DataLoader(val_set, batch_size=128, shuffle=False, drop_last=False, num_workers=2)\n",
        "test_loader = data.DataLoader(test_set, batch_size=128, shuffle=False, drop_last=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptL0k2bjFicz"
      },
      "outputs": [],
      "source": [
        "# Define the transformations for test and training datasets\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(DATA_MEANS, DATA_STD)\n",
        "])\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=0.1),\n",
        "    transforms.ToTensor(),  \n",
        "    transforms.Normalize(DATA_MEANS, DATA_STD)\n",
        "])\n",
        "\n",
        "\n",
        "# Loading the training dataset. We need to split it into a training and validation part\n",
        "# We need to do a little trick because the validation set should not use the augmentation.\n",
        "train_dataset = CIFAR10(root=DATASET_PATH, train=True, transform=train_transform, download=True)\n",
        "val_dataset = CIFAR10(root=DATASET_PATH, train=True, transform=test_transform, download=True)\n",
        "set_seed(42)\n",
        "train_set, _ = torch.utils.data.random_split(train_dataset, [45000, 5000])\n",
        "set_seed(42)\n",
        "_, val_set = torch.utils.data.random_split(val_dataset, [45000, 5000])\n",
        "\n",
        "# Loading the test set\n",
        "test_set = CIFAR10(root=DATASET_PATH, train=False, transform=test_transform, download=True)\n",
        "\n",
        "# We define a set of data loaders that we can use for various purposes later.\n",
        "train_loader = data.DataLoader(train_set, batch_size=128, shuffle=True, drop_last=True, pin_memory=True, num_workers=2)\n",
        "val_loader = data.DataLoader(val_set, batch_size=128, shuffle=False, drop_last=False, num_workers=2)\n",
        "test_loader = data.DataLoader(test_set, batch_size=128, shuffle=False, drop_last=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMDHq_cpa8TK"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms.autoaugment import AutoAugmentPolicy\n",
        "\n",
        "# Define the transformations for test and training datasets\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(DATA_MEANS, DATA_STD)\n",
        "])\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "                    transforms.AutoAugment(AutoAugmentPolicy.CIFAR10),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize(DATA_MEANS, DATA_STD)\n",
        "                ])\n",
        "\n",
        "\n",
        "# Loading the training dataset. We need to split it into a training and validation part\n",
        "# We need to do a little trick because the validation set should not use the augmentation.\n",
        "train_dataset = CIFAR10(root=DATASET_PATH, train=True, transform=train_transform, download=True)\n",
        "val_dataset = CIFAR10(root=DATASET_PATH, train=True, transform=test_transform, download=True)\n",
        "set_seed(42)\n",
        "train_set, _ = torch.utils.data.random_split(train_dataset, [45000, 5000])\n",
        "set_seed(42)\n",
        "_, val_set = torch.utils.data.random_split(val_dataset, [45000, 5000])\n",
        "\n",
        "# Loading the test set\n",
        "test_set = CIFAR10(root=DATASET_PATH, train=False, transform=test_transform, download=True)\n",
        "\n",
        "# We define a set of data loaders that we can use for various purposes later.\n",
        "train_loader = data.DataLoader(train_set, batch_size=128, shuffle=True, drop_last=True, pin_memory=True, num_workers=2)\n",
        "val_loader = data.DataLoader(val_set, batch_size=128, shuffle=False, drop_last=False, num_workers=2)\n",
        "test_loader = data.DataLoader(test_set, batch_size=128, shuffle=False, drop_last=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92mcfoJOi5_c"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms\n",
        "import torch.utils.data as data\n",
        "\n",
        "# Step 1: Calculate the mean and standard deviation of the augmented dataset\n",
        "train_dataset = CIFAR10(root=DATASET_PATH, train=True, download=True)\n",
        "\n",
        "augmented_transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=0.1),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "augmented_dataset = CIFAR10(root=DATASET_PATH, train=True, transform=augmented_transform, download=True)\n",
        "\n",
        "augmented_mean = torch.stack([data for data, _ in augmented_dataset], dim=0).mean(axis=(0, 2, 3))\n",
        "augmented_std = torch.stack([data for data, _ in augmented_dataset], dim=0).std(axis=(0, 2, 3))\n",
        "\n",
        "# Step 2: Create a separate Normalize transform with the updated mean and standard deviation\n",
        "normalize_transform = transforms.Normalize(mean=augmented_mean, std=augmented_std)\n",
        "\n",
        "# Step 3: Apply the normalization transform to the dataset loaded with DataLoader\n",
        "train_transform = transforms.Compose([\n",
        "    augmented_transform,\n",
        "    normalize_transform\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    normalize_transform\n",
        "])\n",
        "\n",
        "# Loading the training dataset\n",
        "train_dataset = CIFAR10(root=DATASET_PATH, train=True, transform=train_transform, download=True)\n",
        "val_dataset = CIFAR10(root=DATASET_PATH, train=True, transform=test_transform, download=True)\n",
        "test_dataset = CIFAR10(root=DATASET_PATH, train=False, transform=test_transform, download=True)\n",
        "\n",
        "# DataLoader configurations\n",
        "batch_size = 128\n",
        "num_workers = 2\n",
        "shuffle = True\n",
        "drop_last = True\n",
        "\n",
        "# Creating DataLoaders\n",
        "train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle,\n",
        "                               drop_last=drop_last, num_workers=num_workers)\n",
        "val_loader = data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
        "                             drop_last=False, num_workers=num_workers)\n",
        "test_loader = data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
        "                              drop_last=False, num_workers=num_workers)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03pqmkONmFSX"
      },
      "outputs": [],
      "source": [
        "imgs, _ = next(iter(train_loader))\n",
        "print(\"Batch mean\", imgs.mean(dim=[0,2,3]))\n",
        "print(\"Batch std\", imgs.std(dim=[0,2,3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rggq1vPamFSX"
      },
      "source": [
        "Visualizing images."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_IMAGES = 4\n",
        "images = [train_dataset[idx+11][0] for idx in range(NUM_IMAGES)]\n",
        "orig_images = [Image.fromarray(train_dataset.data[idx+11]) for idx in range(NUM_IMAGES)]\n",
        "orig_images = [test_transform(img) for img in orig_images]\n",
        "\n",
        "img_grid = torchvision.utils.make_grid(torch.stack(images + orig_images, dim=0), nrow=4, normalize=True, pad_value=0.5)\n",
        "img_grid = img_grid.permute(1, 2, 0)\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.title(\"Augmentation examples on CIFAR10\")\n",
        "plt.imshow(img_grid)\n",
        "plt.axis('off')\n",
        "plt.savefig(\"augmentation_plot_standard.png\")  # Save the plot as a PNG file\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "eUvOVCWxMif9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePIqKb2qmFSX"
      },
      "outputs": [],
      "source": [
        "NUM_IMAGES = 4\n",
        "images = [train_dataset[idx+11][0] for idx in range(NUM_IMAGES)]\n",
        "orig_images = [Image.fromarray(train_dataset.data[idx+11]) for idx in range(NUM_IMAGES)]\n",
        "orig_images = [test_transform(img) for img in orig_images]\n",
        "\n",
        "img_grid = torchvision.utils.make_grid(torch.stack(images + orig_images, dim=0), nrow=4, normalize=True, pad_value=0.5)\n",
        "img_grid = img_grid.permute(1, 2, 0)\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.title(\"Augmentation examples on CIFAR10\")\n",
        "plt.imshow(img_grid)\n",
        "plt.axis('off')\n",
        "plt.savefig(\"augmentation_plot_adjusted.png\")  # Save the plot as a PNG file\n",
        "plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NgTPGCZmFSY"
      },
      "source": [
        "Import PyTorch Lightning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-_kGQ0BmFSY"
      },
      "outputs": [],
      "source": [
        "# PyTorch Lightning\n",
        "try:\n",
        "    import pytorch_lightning as pl\n",
        "except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n",
        "    !pip install --quiet pytorch-lightning>=1.5\n",
        "    import pytorch_lightning as pl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M83ppgOrmFSY"
      },
      "outputs": [],
      "source": [
        "# Setting the seed\n",
        "pl.seed_everything(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nb1FUBYXmFSY"
      },
      "source": [
        "Defining the default module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjhIInTEmFSY"
      },
      "outputs": [],
      "source": [
        "class CIFARModule(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, model_name, model_hparams, optimizer_name, optimizer_hparams):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            model_name - Name of the model/CNN to run. Used for creating the model (see function below)\n",
        "            model_hparams - Hyperparameters for the model, as dictionary.\n",
        "            optimizer_name - Name of the optimizer to use. Currently supported: Adam, SGD\n",
        "            optimizer_hparams - Hyperparameters for the optimizer, as dictionary. This includes learning rate, weight decay, etc.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # Exports the hyperparameters to a YAML file, and create \"self.hparams\" namespace\n",
        "        self.save_hyperparameters()\n",
        "        # Create model\n",
        "        self.model = create_model(model_name, model_hparams)\n",
        "        # Create loss module\n",
        "        self.loss_module = nn.CrossEntropyLoss()\n",
        "        # Example input for visualizing the graph in Tensorboard\n",
        "        self.example_input_array = torch.zeros((1, 3, 32, 32), dtype=torch.float32)\n",
        "\n",
        "    def forward(self, imgs):\n",
        "        # Forward function that is run when visualizing the graph\n",
        "        return self.model(imgs)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # We will support Adam or SGD as optimizers.\n",
        "        if self.hparams.optimizer_name == \"Adam\":\n",
        "            # AdamW is Adam with a correct implementation of weight decay (see here for details: https://arxiv.org/pdf/1711.05101.pdf)\n",
        "            optimizer = optim.AdamW(\n",
        "                self.parameters(), **self.hparams.optimizer_hparams)\n",
        "        elif self.hparams.optimizer_name == \"SGD\":\n",
        "            optimizer = optim.SGD(self.parameters(), **self.hparams.optimizer_hparams)\n",
        "        else:\n",
        "            assert False, f\"Unknown optimizer: \\\"{self.hparams.optimizer_name}\\\"\"\n",
        "\n",
        "        # We will reduce the learning rate by 0.1 after 100 and 150 epochs\n",
        "        scheduler = optim.lr_scheduler.MultiStepLR(\n",
        "            optimizer, milestones=[100, 150], gamma=0.1)\n",
        "        return [optimizer], [scheduler]\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # \"batch\" is the output of the training data loader.\n",
        "        imgs, labels = batch\n",
        "        preds = self.model(imgs)\n",
        "        loss = self.loss_module(preds, labels)\n",
        "        acc = (preds.argmax(dim=-1) == labels).float().mean()\n",
        "\n",
        "        # Logs the accuracy per epoch to tensorboard (weighted average over batches)\n",
        "        self.log('train_acc', acc, on_step=False, on_epoch=True)\n",
        "        self.log('train_loss', loss)\n",
        "        return loss  # Return tensor to call \".backward\" on\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        imgs, labels = batch\n",
        "        preds = self.model(imgs).argmax(dim=-1)\n",
        "        acc = (labels == preds).float().mean()\n",
        "        # By default logs it per epoch (weighted average over batches)\n",
        "        self.log('val_acc', acc)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        imgs, labels = batch\n",
        "        preds = self.model(imgs).argmax(dim=-1)\n",
        "        acc = (labels == preds).float().mean()\n",
        "        # By default logs it per epoch (weighted average over batches), and returns it afterwards\n",
        "        self.log('test_acc', acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXNxzjoEmFSY"
      },
      "source": [
        "Import callbacks.\n",
        "\n",
        "Callbacks - self-contained functions that contain the non-essential logic of Lightning Module. They are usually called after finishing a training epoch, but can also influence other parts of the training loop.\n",
        "\n",
        "`LearningRateMonitor` adds the current learning rate to the TensorBoard, which helps to verify that the learning rate scheduler works correctly\n",
        "`ModelCheckpoint` allows to customize the saving routine of the checkpoints, i.e. how many checkpoints to keep, when to save, which metric to look out for, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5mpEsQpmFSY"
      },
      "outputs": [],
      "source": [
        "# Callbacks \n",
        "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3waO3TY2mFSY"
      },
      "source": [
        "`model_dict` - dictionary to hold multiple different models with the same Lightning module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QxRkWozmFSY"
      },
      "outputs": [],
      "source": [
        "model_dict = {}\n",
        "\n",
        "def create_model(model_name, model_hparams):\n",
        "    if model_name in model_dict:\n",
        "        return model_dict[model_name](**model_hparams)\n",
        "    else:\n",
        "        assert False, f\"Unknown model name \\\"{model_name}\\\". Available models are: {str(model_dict.keys())}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ul8GABrmFSZ"
      },
      "outputs": [],
      "source": [
        "# name to function dict\n",
        "act_fn_by_name = {\n",
        "    \"tanh\": nn.Tanh,\n",
        "    \"relu\": nn.ReLU,\n",
        "    \"leakyrelu\": nn.LeakyReLU,\n",
        "    \"gelu\": nn.GELU\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAmdQcWZmFSZ"
      },
      "source": [
        "Defining the `train_model` function. \n",
        "\n",
        "`train_model` function takes a model as a parameter and trains the model using `trainer.fit` function and using training and validation dataset. Once the model is trained, it tests the best model on validation and test dataset and gives the result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXSfH3vqmFSZ"
      },
      "outputs": [],
      "source": [
        "def train_model(model_name, save_name=None, **kwargs):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "        model_name - Name of the model you want to run. Is used to look up the class in \"model_dict\"\n",
        "        save_name (optional) - If specified, this name will be used for creating the checkpoint and logging directory.\n",
        "    \"\"\"\n",
        "    if save_name is None:\n",
        "        save_name = model_name\n",
        "        \n",
        "    # Create a PyTorch Lightning trainer with the generation callback\n",
        "    trainer = pl.Trainer(default_root_dir=os.path.join(CHECKPOINT_PATH, save_name),                          # Where to save models\n",
        "                         accelerator=\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",                     # We run on a GPU (if possible)\n",
        "                         devices=1,                                                                          # How many GPUs/CPUs we want to use (1 is enough for the notebooks)\n",
        "                         max_epochs=1,                                                                     # How many epochs to train for if no patience is set\n",
        "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\"),  # Save the best checkpoint based on the maximum val_acc recorded. Saves only weights and not optimizer\n",
        "                                    LearningRateMonitor(\"epoch\")],                                           # Log learning rate every epoch\n",
        "                         enable_progress_bar=True)                                                           # Set to False if you do not want a progress bar\n",
        "    trainer.logger._log_graph = True         # If True, we plot the computation graph in tensorboard\n",
        "    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n",
        "    \n",
        "    # Check whether pretrained model exists. If yes, load it and skip training\n",
        "    pretrained_filename = os.path.join(CHECKPOINT_PATH, save_name + \".ckpt\")\n",
        "    if os.path.isfile(pretrained_filename):\n",
        "        print(f\"Found pretrained model at {pretrained_filename}, loading...\")\n",
        "        model = CIFARModule.load_from_checkpoint(pretrained_filename) # Automatically loads the model with the saved hyperparameters\n",
        "    else:\n",
        "        pl.seed_everything(42) # To be reproducable\n",
        "        model = CIFARModule(model_name=model_name, **kwargs)\n",
        "        trainer.fit(model, train_loader, val_loader)\n",
        "        model = CIFARModule.load_from_checkpoint(trainer.checkpoint_callback.best_model_path) # Load best checkpoint after training\n",
        "        \n",
        "    # Test best model on validation and test set\n",
        "    val_result = trainer.test(model, val_loader, verbose=False)\n",
        "    test_result = trainer.test(model, test_loader, verbose=False)\n",
        "    result = {\"test\": test_result[0][\"test_acc\"], \"val\": val_result[0][\"test_acc\"]}\n",
        "    \n",
        "    return model, result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XrWLAZaKi-H"
      },
      "outputs": [],
      "source": [
        "def train_model_ownModels(model_name, save_name=None, **kwargs):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "        model_name - Name of the model you want to run. Is used to look up the class in \"model_dict\"\n",
        "        save_name (optional) - If specified, this name will be used for creating the checkpoint and logging directory.\n",
        "    \"\"\"\n",
        "    if save_name is None:\n",
        "        save_name = model_name\n",
        "        \n",
        "    # Create a PyTorch Lightning trainer with the generation callback\n",
        "    trainer = pl.Trainer(default_root_dir=os.path.join(CHECKPOINT_PATH, save_name),                          # Where to save models\n",
        "                         accelerator=\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",                     # We run on a GPU (if possible)\n",
        "                         devices=1,                                                                          # How many GPUs/CPUs we want to use (1 is enough for the notebooks)\n",
        "                         max_epochs=10,                                                                     # How many epochs to train for if no patience is set\n",
        "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\"),  # Save the best checkpoint based on the maximum val_acc recorded. Saves only weights and not optimizer\n",
        "                                    LearningRateMonitor(\"epoch\")],                                           # Log learning rate every epoch\n",
        "                         enable_progress_bar=True)                                                           # Set to False if you do not want a progress bar\n",
        "    trainer.logger._log_graph = True         # If True, we plot the computation graph in tensorboard\n",
        "    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n",
        "    \n",
        "    pl.seed_everything(42) # To be reproducable\n",
        "    model = CIFARModule(model_name=model_name, **kwargs)\n",
        "    trainer.fit(model, train_loader, val_loader)\n",
        "    model = CIFARModule.load_from_checkpoint(trainer.checkpoint_callback.best_model_path) # Load best checkpoint after training\n",
        "        \n",
        "    # Test best model on validation and test set\n",
        "    val_result = trainer.test(model, val_loader, verbose=False)\n",
        "    test_result = trainer.test(model, test_loader, verbose=False)\n",
        "    result = {\"test\": test_result[0][\"test_acc\"], \"val\": val_result[0][\"test_acc\"]}\n",
        "        \n",
        "    return model, result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBwEVcmkmFSe"
      },
      "source": [
        "## ***ResNet***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djd9u1vrcXX9"
      },
      "source": [
        "**ResNet** - applies a non-linear activation function after the skip connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnIO0AZzmFSe"
      },
      "outputs": [],
      "source": [
        "class ResNetBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, c_in, act_fn, subsample=False, c_out=-1):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            c_in - Number of input features\n",
        "            act_fn - Activation class constructor (e.g. nn.ReLU)\n",
        "            subsample - If True, we want to apply a stride inside the block and reduce the output shape by 2 in height and width\n",
        "            c_out - Number of output features. Note that this is only relevant if subsample is True, as otherwise, c_out = c_in\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        if not subsample:\n",
        "            c_out = c_in\n",
        "            \n",
        "        # Network representing F\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(c_in, c_out, kernel_size=3, padding=1, stride=1 if not subsample else 2, bias=False),  # No bias needed as the Batch Norm handles it\n",
        "            nn.BatchNorm2d(c_out),\n",
        "            act_fn(),\n",
        "            nn.Conv2d(c_out, c_out, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(c_out)\n",
        "        )\n",
        "        \n",
        "        # 1x1 convolution with stride 2 means we take the upper left value, and transform it to new output size\n",
        "        self.downsample = nn.Conv2d(c_in, c_out, kernel_size=1, stride=2) if subsample else None\n",
        "        self.act_fn = act_fn()\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.net(x)\n",
        "        if self.downsample is not None:\n",
        "            x = self.downsample(x)\n",
        "        out = z + x\n",
        "        out = self.act_fn(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5xHGOR7mFSf"
      },
      "outputs": [],
      "source": [
        "resnet_blocks_by_name = {\n",
        "    \"ResNetBlock\": ResNetBlock,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJzhhMlzmFSf"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=10, num_blocks=[3,3,3], c_hidden=[16,32,64], act_fn_name=\"relu\", block_name=\"ResNetBlock\", **kwargs):\n",
        "        \"\"\"\n",
        "        Inputs: \n",
        "            num_classes - Number of classification outputs (10 for CIFAR10)\n",
        "            num_blocks - List with the number of ResNet blocks to use. The first block of each group uses downsampling, except the first.\n",
        "            c_hidden - List with the hidden dimensionalities in the different blocks. Usually multiplied by 2 the deeper we go.\n",
        "            act_fn_name - Name of the activation function to use, looked up in \"act_fn_by_name\"\n",
        "            block_name - Name of the ResNet block, looked up in \"resnet_blocks_by_name\"\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        assert block_name in resnet_blocks_by_name\n",
        "        self.hparams = SimpleNamespace(num_classes=num_classes, \n",
        "                                       c_hidden=c_hidden, \n",
        "                                       num_blocks=num_blocks, \n",
        "                                       act_fn_name=act_fn_name,\n",
        "                                       act_fn=act_fn_by_name[act_fn_name],\n",
        "                                       block_class=resnet_blocks_by_name[block_name])\n",
        "        self._create_network()\n",
        "        self._init_params()\n",
        "\n",
        "    def _create_network(self):\n",
        "        c_hidden = self.hparams.c_hidden\n",
        "        \n",
        "        # A first convolution on the original image to scale up the channel size\n",
        "        if self.hparams.block_class == PreActResNetBlock: # => Don't apply non-linearity on output\n",
        "            self.input_net = nn.Sequential(\n",
        "                nn.Conv2d(3, c_hidden[0], kernel_size=3, padding=1, bias=False)\n",
        "            )\n",
        "        else:\n",
        "            self.input_net = nn.Sequential(\n",
        "                nn.Conv2d(3, c_hidden[0], kernel_size=3, padding=1, bias=False),\n",
        "                nn.BatchNorm2d(c_hidden[0]),\n",
        "                self.hparams.act_fn()\n",
        "            )\n",
        "        \n",
        "        # Creating the ResNet blocks\n",
        "        blocks = []\n",
        "        for block_idx, block_count in enumerate(self.hparams.num_blocks):\n",
        "            for bc in range(block_count):\n",
        "                subsample = (bc == 0 and block_idx > 0) # Subsample the first block of each group, except the very first one.\n",
        "                blocks.append(\n",
        "                    self.hparams.block_class(c_in=c_hidden[block_idx if not subsample else (block_idx-1)],\n",
        "                                             act_fn=self.hparams.act_fn,\n",
        "                                             subsample=subsample,\n",
        "                                             c_out=c_hidden[block_idx])\n",
        "                )\n",
        "        self.blocks = nn.Sequential(*blocks)\n",
        "        \n",
        "        # Mapping to classification output\n",
        "        self.output_net = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1,1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(c_hidden[-1], self.hparams.num_classes)\n",
        "        )\n",
        "\n",
        "    def _init_params(self):\n",
        "        # Based on our discussion in Tutorial 4, we should initialize the convolutions according to the activation function\n",
        "        # Fan-out focuses on the gradient distribution, and is commonly used in ResNets\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity=self.hparams.act_fn_name)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_net(x)\n",
        "        x = self.blocks(x)\n",
        "        x = self.output_net(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFcmGbpQmFSf"
      },
      "outputs": [],
      "source": [
        "model_dict[\"ResNet\"] = ResNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KRfET6mmFSg"
      },
      "source": [
        "Training the ResNet model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzgtvHolmFSg"
      },
      "outputs": [],
      "source": [
        "resnet_model, resnet_results = train_model(model_name=\"ResNet\", \n",
        "                                           model_hparams={\"num_classes\": 10,\n",
        "                                                          \"c_hidden\": [16,32,64],\n",
        "                                                          \"num_blocks\": [3,3,3],\n",
        "                                                          \"act_fn_name\": \"relu\"}, \n",
        "                                           optimizer_name=\"SGD\",\n",
        "                                           optimizer_hparams={\"lr\": 0.1,\n",
        "                                                              \"momentum\": 0.9,\n",
        "                                                              \"weight_decay\": 1e-4})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_results"
      ],
      "metadata": {
        "id": "JPZ-4r6DsjON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUuI1yONYhd_"
      },
      "source": [
        "### Tensorboard log (ResNet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFNMEgf1Ys9Y"
      },
      "outputs": [],
      "source": [
        "# Load tensorboard extension\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nm__Ff-CmFSg"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir ./tensorboards/ResNet/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9oebxwCmFSg"
      },
      "source": [
        "## ***DenseNet***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8_Qt9D0bFwn"
      },
      "source": [
        "We split the implementation of the layers in DenseNet into three parts: a `DenseLayer`, and a `DenseBlock`, and a `TransitionLayer`.\n",
        "\n",
        "`DenseLayer` - implements a single layer inside a dense block. It applies a 1x1 convolution for dimensionality reduction with a subsequential 3x3 convolution. The output channels are concatenated to the originals and returned.\n",
        "\n",
        "`DenseBlock` - summarizes multiple dense layers applied in sequence. Each dense layer takes as input the original input concatenated with all previous layers' feature maps.\n",
        "\n",
        "`TransitionLayer` - takes as input the final output of a dense block and reduces its channel dimensionality using a 1x1 convolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAgzY-D2mFSg"
      },
      "outputs": [],
      "source": [
        "class DenseLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, c_in, bn_size, growth_rate, act_fn):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            c_in - Number of input channels\n",
        "            bn_size - Bottleneck size (factor of growth rate) for the output of the 1x1 convolution. Typically between 2 and 4.\n",
        "            growth_rate - Number of output channels of the 3x3 convolution\n",
        "            act_fn - Activation class constructor (e.g. nn.ReLU)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.BatchNorm2d(c_in),\n",
        "            act_fn(),\n",
        "            nn.Conv2d(c_in, bn_size * growth_rate, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(bn_size * growth_rate),\n",
        "            act_fn(),\n",
        "            nn.Conv2d(bn_size * growth_rate, growth_rate, kernel_size=3, padding=1, bias=False)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.net(x)\n",
        "        out = torch.cat([out, x], dim=1)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-kUC-epmFSh"
      },
      "outputs": [],
      "source": [
        "class DenseBlock(nn.Module):\n",
        "    \n",
        "    def __init__(self, c_in, num_layers, bn_size, growth_rate, act_fn):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            c_in - Number of input channels\n",
        "            num_layers - Number of dense layers to apply in the block\n",
        "            bn_size - Bottleneck size to use in the dense layers\n",
        "            growth_rate - Growth rate to use in the dense layers\n",
        "            act_fn - Activation function to use in the dense layers\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        for layer_idx in range(num_layers):\n",
        "            layers.append(\n",
        "                DenseLayer(c_in=c_in + layer_idx * growth_rate, # Input channels are original plus the feature maps from previous layers\n",
        "                           bn_size=bn_size,\n",
        "                           growth_rate=growth_rate,\n",
        "                           act_fn=act_fn)\n",
        "            )\n",
        "        self.block = nn.Sequential(*layers)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.block(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcU6o6gNmFSh"
      },
      "outputs": [],
      "source": [
        "class TransitionLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, c_in, c_out, act_fn):\n",
        "        super().__init__()\n",
        "        self.transition = nn.Sequential(\n",
        "            nn.BatchNorm2d(c_in),\n",
        "            act_fn(),\n",
        "            nn.Conv2d(c_in, c_out, kernel_size=1, bias=False),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2) # Average the output for each 2x2 pixel group\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.transition(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qEDAUHlmFSh"
      },
      "outputs": [],
      "source": [
        "class DenseNet(nn.Module):\n",
        "    \n",
        "    def __init__(self, num_classes=10, num_layers=[6,6,6,6], bn_size=2, growth_rate=16, act_fn_name=\"relu\", **kwargs):\n",
        "        super().__init__()\n",
        "        self.hparams = SimpleNamespace(num_classes=num_classes,\n",
        "                                       num_layers=num_layers,\n",
        "                                       bn_size=bn_size,\n",
        "                                       growth_rate=growth_rate,\n",
        "                                       act_fn_name=act_fn_name,\n",
        "                                       act_fn=act_fn_by_name[act_fn_name])\n",
        "        self._create_network()\n",
        "        self._init_params()\n",
        "        \n",
        "    def _create_network(self):\n",
        "        c_hidden = self.hparams.growth_rate * self.hparams.bn_size # The start number of hidden channels\n",
        "        \n",
        "        # A first convolution on the original image to scale up the channel size\n",
        "        self.input_net = nn.Sequential(\n",
        "            nn.Conv2d(3, c_hidden, kernel_size=3, padding=1) # No batch norm or activation function as done inside the Dense layers\n",
        "        )\n",
        "        \n",
        "        # Creating the dense blocks, eventually including transition layers\n",
        "        blocks = []\n",
        "        for block_idx, num_layers in enumerate(self.hparams.num_layers):\n",
        "            blocks.append( \n",
        "                DenseBlock(c_in=c_hidden, \n",
        "                           num_layers=num_layers, \n",
        "                           bn_size=self.hparams.bn_size,\n",
        "                           growth_rate=self.hparams.growth_rate,\n",
        "                           act_fn=self.hparams.act_fn)\n",
        "            )\n",
        "            c_hidden = c_hidden + num_layers * self.hparams.growth_rate # Overall output of the dense block\n",
        "            if block_idx < len(self.hparams.num_layers)-1: # Don't apply transition layer on last block\n",
        "                blocks.append(\n",
        "                    TransitionLayer(c_in=c_hidden,\n",
        "                                    c_out=c_hidden // 2,\n",
        "                                    act_fn=self.hparams.act_fn))\n",
        "                c_hidden = c_hidden // 2\n",
        "                \n",
        "        self.blocks = nn.Sequential(*blocks)\n",
        "        \n",
        "        # Mapping to classification output\n",
        "        self.output_net = nn.Sequential(\n",
        "            nn.BatchNorm2d(c_hidden), # The features have not passed a non-linearity until here.\n",
        "            self.hparams.act_fn(),\n",
        "            nn.AdaptiveAvgPool2d((1,1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(c_hidden, self.hparams.num_classes)\n",
        "        )\n",
        "\n",
        "    def _init_params(self):\n",
        "        # Based on our discussion in Tutorial 4, we should initialize the convolutions according to the activation function\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, nonlinearity=self.hparams.act_fn_name)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_net(x)\n",
        "        x = self.blocks(x)\n",
        "        x = self.output_net(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0NIg_LOmFSh"
      },
      "outputs": [],
      "source": [
        "model_dict[\"DenseNet\"] = DenseNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NnH2COYmFSh"
      },
      "source": [
        "Training the DenseNet model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgKgqzXMmFSh"
      },
      "outputs": [],
      "source": [
        "densenet_model, densenet_results = train_model(model_name=\"DenseNet\", \n",
        "                                               model_hparams={\"num_classes\": 10,\n",
        "                                                              \"num_layers\": [6,6,6,6],\n",
        "                                                              \"bn_size\": 2,\n",
        "                                                              \"growth_rate\": 16,\n",
        "                                                              \"act_fn_name\": \"relu\"}, \n",
        "                                               optimizer_name=\"Adam\",\n",
        "                                               optimizer_hparams={\"lr\": 1e-3,\n",
        "                                                                  \"weight_decay\": 1e-4})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "densenet_results"
      ],
      "metadata": {
        "id": "tSR_QegGsvpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHUMxxIZmFSh"
      },
      "source": [
        "### Tensorboard log (DenseNet)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "NcRkmCxXucMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y29LDVpLmFSh",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir ./tensorboards/DenseNet/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-o-fYQJEIZPF"
      },
      "source": [
        "## **Own Models with adjusted Augmented Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHCogss7I2Kh"
      },
      "source": [
        "ResNet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "id": "lMoRyzmuMp0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jc_93p3zJWzT"
      },
      "outputs": [],
      "source": [
        "model_dict[\"ResNet\"] = ResNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFn5TvDaIfAE"
      },
      "outputs": [],
      "source": [
        "resnet_model_own, resnet_results_own = train_model_ownModels(model_name=\"ResNet\", \n",
        "                                           model_hparams={\"num_classes\": 10,\n",
        "                                                          \"c_hidden\": [16,32,64],\n",
        "                                                          \"num_blocks\": [3,3,3],\n",
        "                                                          \"act_fn_name\": \"relu\"}, \n",
        "                                           optimizer_name=\"SGD\",\n",
        "                                           optimizer_hparams={\"lr\": 0.1,\n",
        "                                                              \"momentum\": 0.9,\n",
        "                                                              \"weight_decay\": 1e-4})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_results_own"
      ],
      "metadata": {
        "id": "MnOB7zx4v8b7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtDRFwbpI38u"
      },
      "source": [
        "DenseNet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "id": "6zdF-4KIsx8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_dict[\"DenseNet\"] = DenseNet"
      ],
      "metadata": {
        "id": "vtnm4gbi3Yq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qv_yUBHbI5Xg"
      },
      "outputs": [],
      "source": [
        "densenet_model_own, densenet_results_own = train_model_ownModels(model_name=\"DenseNet\", \n",
        "                                               model_hparams={\"num_classes\": 10,\n",
        "                                                              \"num_layers\": [6,6,6,6],\n",
        "                                                              \"bn_size\": 2,\n",
        "                                                              \"growth_rate\": 16,\n",
        "                                                              \"act_fn_name\": \"relu\"}, \n",
        "                                               optimizer_name=\"Adam\",\n",
        "                                               optimizer_hparams={\"lr\": 1e-3,\n",
        "                                                                  \"weight_decay\": 1e-4})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "densenet_results_own"
      ],
      "metadata": {
        "id": "pcUP4s85I6Z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "densenet_model_own"
      ],
      "metadata": {
        "id": "rWYJNnpX8Wx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUM8HVymmFSh"
      },
      "source": [
        "## **Conclusion and Comparison**\n",
        "\n",
        "Comparing the results between the models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wyz9yTYomFSi"
      },
      "outputs": [],
      "source": [
        "%%html\n",
        "<!-- Some HTML code to increase font size in the following table -->\n",
        "<style>\n",
        "th {font-size: 120%;}\n",
        "td {font-size: 120%;}\n",
        "</style>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ob2XBYLHmFSi"
      },
      "outputs": [],
      "source": [
        "import tabulate\n",
        "from IPython.display import display, HTML\n",
        "all_models = [\n",
        "    (\"ResNet\", resnet_results, resnet_model),\n",
        "    (\"DenseNet\", densenet_results, densenet_model)\n",
        "]\n",
        "table = [[model_name,\n",
        "          f\"{100.0*model_results['val']:4.2f}%\",\n",
        "          f\"{100.0*model_results['test']:4.2f}%\",\n",
        "          \"{:,}\".format(sum([np.prod(p.shape) for p in model.parameters()]))]\n",
        "         for model_name, model_results, model in all_models]\n",
        "display(HTML(tabulate.tabulate(table, tablefmt='html', headers=[\"Model\", \"Val Accuracy\", \"Test Accuracy\", \"Num Parameters\"])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCU8JW15FyYF"
      },
      "outputs": [],
      "source": [
        "accuracies = [87.57, 93.57, 94.81, 95.81, 96.00]\n",
        "\n",
        "# Plotting the accuracies\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "models = [\"Doon et al.\", \"He et al.\", \"Huang et al.\", \"Zagoruyko et al.\", \"Kabir\"]\n",
        "plt.bar(models, accuracies)\n",
        "plt.xlabel(\"Papers\")\n",
        "plt.ylabel(\"Accuracy on CIFAR-10\")\n",
        "plt.title(\"Comparison of Model Accuracies on CIFAR-10\")\n",
        "plt.xticks(rotation=15)\n",
        "plt.ylim(85, 100)  # Adjust the y-axis limits if necessary\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "accuracies = [87.57, 93.57, 94.81, 95.81, 96.00, 70.5, 72.6, 91.1, 90.2]\n",
        "\n",
        "# Separate the original results and additional results\n",
        "original_accuracies = accuracies[:5]\n",
        "additional_accuracies = accuracies[5:]\n",
        "\n",
        "# Adjusting the figure size\n",
        "plt.figure(figsize=(8, 4))  # Set the width and height of the figure in inches\n",
        "\n",
        "# Plotting the original accuracies as dots\n",
        "models = [\"Doon et al.\", \"He et al.\", \"Huang et al.\", \"Zagoruyko et al.\", \"Kabir\"]\n",
        "plt.plot(models, original_accuracies, 'o', label='State-of-the-Art Results')\n",
        "\n",
        "# Plotting the additional accuracies as stars\n",
        "additional_models = [\"Simple CNN\", \"CNN (Optimized hyperparameters)\", \"ResNet\", \"DenseNet\"]\n",
        "plt.plot(additional_models, additional_accuracies, '*', label='Results')\n",
        "\n",
        "plt.xlabel(\"Papers/Models\")\n",
        "plt.ylabel(\"Accuracy on CIFAR-10\")\n",
        "plt.xticks(rotation=15)\n",
        "plt.ylim(70, 100)  # Adjust the y-axis limits if necessary\n",
        "plt.legend()\n",
        "\n",
        "plt.savefig(\"results_comparison.png\")  # Save the plot as a PNG file\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "84yTohz_4xdK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "EHT_3C34vs2p"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}